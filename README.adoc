= Tra Acque
:toc:

Progetto di Cloud Computing anno 2022/2023.

== Run

È presente un file docker-compose per fare deploy locale con Docker, si può fare
anche con Skaffold e Minikube (vedi sotto per il deploy in produzione). Per
maggiori informazioni si riporta alla relazione.

Per il deploy con Docker Compose:

```
docker compose up
```

Per il deploy con Skaffold (richiede un cluster Kubernetes, senza agente
GitLab):

```
skaffold dev
```

== Build

Il progetto utilizza le pipeline di GitLab unicamente per fare la build e push
delle immagini dei microservizi. Poiché il progetto è sul piano gratuito
sull'istanza offerta da GitLab, abbiamo deciso di utilizzare una VM Azure per
eseguire i job della pipeline.

== Installazione del runner

I seguenti procedimenti sono stati presi dalla documentazione ufficiale: https://docs.gitlab.com/runner/install/linux-manually.html#using-binary-file

1. Si scarica l'eseguibile:

```
$ sudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64
```

2. Si danno i permessi di esecuzione all'eseguibile:

```
$ sudo chmod +x /usr/local/bin/gitlab-runner
```

3. Si crea un utente specifico per il runner:

```
$ sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash
```

4. Si installa il runner (cioè crea i file di servizio per systemd) e lo si
   avvia. Nel primo avvio avverrà la configurazione, bisogna scegliere come
   esecutore `docker` e come immagine di default `alpine:latest`:

```
$ sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner
$ sudo gitlab-runner start
```

5. Si registra il runnero con il token fornito dalla UI di GitLab nella
   repository:

```
sudo gitlab-runner register --url https://gitlab.com/ --registration-token $REGISTRATION_TOKEN
```

== Configurazione del runner

La configurazione del runner è salvata nel file
`/etc/gitlab-runner/config.toml`, quella di default va modificata in modo da
renderla ottimale per il progetto. Bisogna apportare le modifiche ai campi
indicati:

```
concurrent = 3

[[runners]]
  [runners.docker]
    privileged = true
    security_opt = ["seccomp=unconfined"]
```

È necessario eseguire i job con l'utente root per vari limiti di Docker che come
conseguenza impatta Buildah (in particopare di seccomp).

Infine è necessario ravviare il runner, controllare per sicurezza la validità
della configurazione e lo stato:

```
$ sudo gitlab-runner restart
$ sudo gitlab-runner status
$ sudo gitlab-runner verify
```

Abbiamo notato che, per ovvi motivi, i job eseguiti sulla VM sono un po' più
lenti rispetto ai runner pubblici di GitLab, ma almeno non abbiamo il limite dei
minuti.

== Deploy

Per fare il deploy usiamo il workflow GitOps in versione pull: https://www.gitops.tech/

È necessario configurare un cluster Kubernetes in modo appropriato come di
seguente.

=== Cluster minikube

È necessario fermare ed eliminare un cluster k8s se già attivo. Il motivo è che
bisogna creare un nuovo cluster con più CPU e memoria RAM assegnata.

```
$ minikube stop
$ minikube delete
$ minikube start --cpus 3 --memory 5000
```

Bisogna abilitare il componente aggiuntivo `ingress`, perché verrà utilizzato
dal servizio delle fontanelle:

```
$ minikube addons enable ingress
```

=== Gestione dei segreti

Per gestire i segreti nella repository per poi fare il deploy sul cluster k8s,
utilizziamo SealedSecrets, un sistema sviluppato da Bitnami che agevola la
creazione, diffusione e rilascio degli oggetti di tipo Secret su cluster
Kubernetes. Maggiori informazioni sul progetto ufficiale: https://github.com/bitnami-labs/sealed-secrets

Funzionamento: i segreti sono salvati nella repository in oggetti di tipo
`SealedSecret`, tali segreti nel momento del deploy vengono decrittati da un
controller presente nel cluster che li trasforma in oggetti di tipo `Secret`,
per cui utilizzabili come riferimento da altri oggetti.

Per ovvi motivi la chiave privata, che è presente nel cluster, non è stata
condivisa. Per cui in caso di deploy personale è necessario ricreare i segreti.

=== Installazione del controller

Viene utilizzato Helm per installare il controller, come riportato dalla
documentazione ufficiale: https://github.com/bitnami-labs/sealed-secrets#helm-chart

Di seguito i comandi da eseguire:

```
$ helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
$ helm install sealed-secrets -n kube-system \
    --set-string fullnameOverride=sealed-secrets-controller \
    sealed-secrets/sealed-secrets
```

Per poter creare i segreti è necessario utilizzare il tool fornito in coppia con
il controllore. Per maggiori informazioni si riporta alla documentazione
ufficiale: https://github.com/bitnami-labs/sealed-secrets#usage

Per ultimo, poiché noi utilizziamo delle VM effimere, è necessario estrarre la
chiave privata (e pubblica) che è stata generata (la prima volta) per poi
ripristinarla al momento della creazione di un nuovo cluster:

```
$ kubectl get secret -n kube-system \
    -l sealedsecrets.bitnami.com/sealed-secrets-key \
    -o yaml >main.key
```

La chiave pubblica invece si può estrarre con il seguente comando (se si vuole
creare segreti senza avere l'accesso al cluster):

```
$ kubeseal --fetch-cert > public.pem
```

Ultimato ciò si può creare e aggiungere nella repository un segreto nel seguente
modo:

```
$ kubeseal --namespace default --cert public.pem \
    --secret-file secret-postgres.yaml --sealed-secret-file postgres.yaml
```

=== Credenziali d'accesso per il registry privato GitLab

Attenzione: dal momento in cui la repository diventa pubblica non è più
necessario effettuare questa configurazione.

Durante il deploy Kubernetes scaricherà le immagini dei servizi dal registro
privato associato alla repository su GitLab. Per questo motivo è necessario
fornire le credenziali come mostrato di seguito riportato dalla documentazione
ufficiale:
https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/#create-a-secret-by-providing-credentials-on-the-command-line

Si assume che l'utente abbia generato un token personale (o un token di
progetto) dalla UI di GitLab con almeno il permesso `read-registry` . Si assume
inoltre di operare sul namespace `default` (usato anche dal deploy).

```
kubectl create secret docker-registry gitlab-credentials \
    --docker-server=registry.gitlab.com \
    --docker-username=GITLAB_USERNAME \
    --docker-password=GITLAB_TOKEN \
    --docker-email=GITLAB_EMAIL
```

Dove:

* `GITLAB_USERNAME` è il nome utente di chi genera il token;
* `GITLAB_TOKEN` è il token generato da GitLab;
* `GITLAB_EMAIL` è l'email associata all'utente che genera il token.

Poiché queste configurazioni vanno fatte una sola volta, e all'inizio della
creazione del cluster, si è deciso di non salvare questi manifesti nella
repository.

I manifesti dei singoli servizi hanno le immagini che puntano alla registro
privato, ma non viene specificato dove recuperare le credenziali per l'accesso.
Ecco perché, per ultimare, è necessario riferire al segreto appena creato:

```
kubectl patch serviceaccount default -p '{"imagePullSecrets": [{"name": "gitlab-credentials"}]}'
```

=== Aggiunta e configurazione dell'agente GitLab

Per installare l'agente sul cluster k8s viene utilizzato in via eccezionale
Helm, che va però installato sulla VM in cui si esegue il cluster. I comandi di
seguito sono riportati dalla documentazione ufficiale (per Debian): https://helm.sh/docs/intro/install/

```
$ curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
$ sudo apt-get install apt-transport-https --yes
$ echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
$ sudo apt-get update
$ sudo apt-get install helm
```

La sequente repository già fornisce un agente collegato che si può trovare al
percorso `.gitlab/agents/tre-acque-petriglia` con la relativa configurazione.
Poiché tale agente è privato, se si vuole provare il deploy è necessario creare
un'altra cartella con un altro nome e all'interno il file (anche vuoto)
`config.yaml`.

Ora è necessario dalla UI di GitLab generare il token relativo per l'agente
specificato (in questo caso si presume sia `tre-acque-petriglia`. Dalla stessa
UI GitLab suggerisce i comandi per installare e configurare l'agente, riportati
qui di seguito:

```
$ helm repo add gitlab https://charts.gitlab.io
$ helm repo update
helm upgrade --install AGENT_NAME gitlab/gitlab-agent \
    --namespace NAMESPACE \
    --create-namespace \
    --set image.tag=v15.8.0 \
    --set config.token=TOKEN \
    --set config.kasAddress=wss://kas.gitlab.com
```

Dove:

* `AGENT_NAME` è il nome dell'agente, in questo caso `tre-acque-petriglia`;
* `NAMESPACE` è il namespace di k8s in cui installare l'agente, in questo caso è
  `gitlab-agent-tre-acque-petriglia`;
* `TOKEN` è il token segreto di connessione, fornito dalla UI di GitLab.

Si suggerisce di usare un namespace diverso da `default`, perché in quest'ultimo
verrà effettuato il deploy dell'applicazione.

A questo punto l'agente è configurato ed è già in esecuzione, appena possibile,
in base alla configurazione presente nel file `config.yaml`, farà il deploy
dell'applicazione. Si possono monitorare gli eventi dell'agente andando a vedere
i log del pod associato con il seguente comando:

```
$ kubectl logs --follow NOME_POD --namespace NAMESPACE
```

Rimpiazzando ovviamente le variabili con i giusti valori dell'agente.

Una volta che il deploy si è stabilizzato, è possibile fare una prova tramite
cURL. Prima bisogna ottenere l'IP del gateway con `kubectl get ingress`.

```
$ kubectl get ingress
NAME       CLASS   HOSTS   ADDRESS        PORTS   AGE
fountain   nginx   *       192.168.49.2   80      69m

$ curl -i 192.168.49.2/fountains
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 16:44:31 GMT
Content-Type: application/json
Content-Length: 2
Connection: keep-alive

[]
```

=== Test con il browser in locale

Una volta che si è avviato e stabilizzato il cluster Kubernetes, è possibile
utilizzare l'applicazione da browser sul proprio computer locale. Per farlo è
necessario creare una serie di port forward in modo che il cluster risulti
accessibile dal computer locale. La seguente figura riassume il funzionamento:

[mermaid]
----
sequenceDiagram
    participant B as Browser
    participant L as Local computer (ssh)
    participant V as Virtual Machine (socat)
    participant C as Kubernetes Cluster

    B ->> L: HTTP Request on localhost:80
    L ->> V: HTTP Request on VM_ADDRESS:80
    V ->> C: HTTP Request on CLUSTER_IP:80

    C ->> V: HTTP Response
    V ->> L: HTTP Response
    L ->> B: HTTP Response
----

Di seguito i passi da seguire:

1. È necessario fare sulla VM port forwarding da localhost dalla porta 80
   all'indirizzo del cluster alla porta 80, dove c'è in ascolto l'ingresso:

```
sudo socat tcp-listen:80,reuseaddr,fork tcp:CLUSTER_IP:80
```

È necessario `sudo` perché si opera su porte privilegiate, e si deve ottenere
l'indirizzo del cluster tramite `minikube ip`.

2. È necessario fare port forwarding tra la VM e il computer locale sulla porta
   80:

```
sudo ssh -p PORT_AZURE IP_AZURE -L 80:localhost:80
```

Anche in questo è necessario `sudo` e bisogna conoscere la porta e l'indirizzo
della VM, tramite l'interfaccia Azure.

3. Infine bisogna aggiornare il file `/etc/hosts` per poter risolvere il dominio
   `tre-acque.com`, utilizzato nell'applicazione frontend, con l'indirizzo di
   localhost. Si deve aggiungere in questo file una riga con il contenuto
   `127.0.0.1 tre-acque.com`.

4. A questo punto si può utilizzare il browser e nagivare all'indirizzo
   `tre-acque.com`, oppure utilizzare strumenti come `curl`.

== Test con `curl`

Di seguito una serie di esempi con curl. Si può consultare la API doc per le
altre api.

1. Aggiunta di una fontana di nome "Fontana Via Armando Diaz" e in delle
   specifiche coordinate:

```
studente@ML-RefVm-605006:~$ curl -i -X POST 192.168.49.2/fountains -H "Content-Type: application/json" -d '{"name": "Fontana Via Armando Diaz", "latitude": 345.91341, "longitude": 315.9123}'
HTTP/1.1 201 Created
Date: Thu, 26 Jan 2023 09:43:15 GMT
Content-Type: application/json
Content-Length: 121
Connection: keep-alive
Location: http://192.168.49.2/fountains/id

{"id":"6f13307c-2bdc-40da-ba72-862bf2fddad7","name":"Fontana Via Armando Diaz","latitude":345.91341,"longitude":315.9123}
```

2. Elenco di tutte le fontane:

```
studente@ML-RefVm-605006:~$ curl -i 192.168.49.2/fountains
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 09:44:15 GMT
Content-Type: application/json
Content-Length: 225
Connection: keep-alive

[{"id":"d61bcdb4-1b7b-4e0b-a438-172a9f5f245f","name":"Test","latitude":345.91341,"longitude":315.9123},{"id":"6f13307c-2bdc-40da-ba72-862bf2fddad7","name":"Fontana Via Armando Diaz","latitude":345.91341,"longitude":315.9123}]
```

3. Aggiunta di un voto alla fontana "Fontana Via Armando Diaz" con valore 5:

```
studente@ML-RefVm-605006:~$ curl -i -X POST 192.168.49.2/fountains/6f13307c-2bdc-40da-ba72-862bf2fddad7/rating -H "Content-Type: application/json" -d 5
HTTP/1.1 201 Created
Date: Thu, 26 Jan 2023 09:45:56 GMT
Content-Type: text/plain; charset=utf-8
Content-Length: 55
Connection: keep-alive

{"id":"3afc0b19-9d5e-11ed-8276-0242ac11000c","value":5}
```

4. Ottenimento del singolo voto:

```
studente@ML-RefVm-605006:~$ curl -i 192.168.49.2/fountains/6f13307c-2bdc-40da-ba72-862bf2fddad7/rating/3afc0b19-9d5e-11ed-8276-0242ac11000c
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 09:46:44 GMT
Content-Type: text/plain; charset=utf-8
Content-Length: 55
Connection: keep-alive

{"id":"3afc0b19-9d5e-11ed-8276-0242ac11000c","value":5}
```

5. Dopo l'aggiunta di un secondo voto alla stessa fontana di valore 2, si
   ottiene la media dei voti per la fontana (valore approssimato per eccesso):

```
studente@ML-RefVm-605006:~$ curl -i 192.168.49.2/fountains/6f13307c-2bdc-40da-ba72-862bf2fddad7/rating
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 09:48:15 GMT
Content-Type: text/plain; charset=utf-8
Content-Length: 1
Connection: keep-alive

4
```

6. Eliminazione di un voto:

```
studente@ML-RefVm-605006:~$ curl -i -X DELETE 192.168.49.2/fountains/6f13307c-2bdc-40da-ba72-862bf2fddad7/rating/3afc0b19-9d5e-11ed-8276-0242ac11000c
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 09:49:38 GMT
Content-Length: 0
Connection: keep-alive

```

7. Ciò ovviamente comporta il cambiamento della media dei voti per la fontana (è
   presente un unico valore 2):

```
studente@ML-RefVm-605006:~$ curl -i 192.168.49.2/fountains/6f13307c-2bdc-40da-ba72-862bf2fddad7/rating
HTTP/1.1 200 OK
Date: Thu, 26 Jan 2023 09:50:12 GMT
Content-Type: text/plain; charset=utf-8
Content-Length: 1
Connection: keep-alive

2
```
